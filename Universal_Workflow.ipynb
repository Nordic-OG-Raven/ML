{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNhstbddO1ZHYWLXj15pk/+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nordic-OG-Raven/ML/blob/main/Universal_Workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Universal Workflow consists of:\n",
        "\n",
        "1) Defining the task\n",
        "\n",
        "2) Developing a model (main focus of this template)\n",
        "\n",
        "3) Deplying a model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pJvA90WhgAY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1) Define the task\n",
        "- What is the prediction target\n"
      ],
      "metadata": {
        "id": "pX23bL3I8L0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV1\n",
        "In this exercise, you will expand last weeks exercise by training pre-trained model.\n",
        "\n",
        "**About the CIFAR-10 dataset**\n",
        "\n",
        "The CIFAR-10 dataset is a widely-used dataset for benchmarking machine learning algorithms, especially in the field of image recognition. It consists of 60,000 32x32 color images in 10 different classes, with 6,000 images per class. The dataset is divided into 50,000 training images and 10,000 test images. The classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. Each image is labeled with one of these 10 classes, making it a standard dataset for evaluating algorithms for image classification tasks.\n",
        "\n",
        "The CIFAR-10 dataset was created by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton and is a subset of the 80 million tiny images dataset. Due to its moderate size and complexity, CIFAR-10 serves as an excellent benchmark for algorithms and techniques in computer vision, particularly for methodologies that are aimed at performing well on small to medium-sized datasets in image recognition tasks."
      ],
      "metadata": {
        "id": "qBwdHfIHquI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV2 - Using a pre-trained ResNet50 model\n",
        "In this exercise, you'll expand on last weeks exercise by adding pre-trained models to the mix. In particular, you'll work with ResNet50, a powerful pre-trained model.Here is the task:\n",
        "\n",
        "Try a ResNet50 with data augmentation on the cifar10 dataset.\n",
        "\n",
        "Two tips:\n",
        "1.   Remember to turn on the GPU. Don't let it stand idle. Whenever you need to take a break, remember to switch it off.\n",
        "2.   When preprocessing the model, do this to avoid errors\n",
        "\n",
        "```\n",
        "# Apply the preprocess_input function\n",
        "x = Lambda(preprocess_input)(x)\n",
        "```\n",
        "\n",
        "This allows arbitrary expressions to be inserted into Keras models.\n"
      ],
      "metadata": {
        "id": "GAqsJKTMlzu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV3 - Building a Mini Exception Model\n",
        "In this exercise, we will explore how far we can push our model performance on the cifar10 dataset. Your task now is to implement modern convnet architecture patterns like batchnorm, seperable depthwise convolutions and residual connections and examine how far this will boost performance."
      ],
      "metadata": {
        "id": "T7E5N_xIlbwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Choose a measure of success\n",
        "- Single-label classification --> Accuracy\n",
        "- Scalar regression --> MAE\n",
        "- Balanced classification --> ROC AUC\n",
        "- Imbalanced CLassification --> Precision and recall\n",
        "- Multi-label Classification --> Mean average precision\n"
      ],
      "metadata": {
        "id": "1ewE7R2Ysh97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Collecting the dataset, and understanding it to check\n",
        "- The reliability of the labels\n",
        "- The quality of the features\n",
        "- The number of data-points\n",
        "\n",
        "Thus, ensure to check for instance,\n",
        "- balance between classes, features, noise etc.\n",
        "  - DL models tend to latch on to noise if that is unbalanced between target classes.\n",
        "  - Data representativeness, e.g. in regards to minorities"
      ],
      "metadata": {
        "id": "1PRR4I598G6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data"
      ],
      "metadata": {
        "id": "TygOoJB0grH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "    num_words=10000)\n",
        "\n",
        "# num_words=10000 - we’ll keep the top 10,000 most frequent words"
      ],
      "metadata": {
        "id": "vXa3IE8zgqUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "Idf_Gc-xt1o0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see the current list of indices:\n",
        "train_data[0]\n",
        "\n",
        "# we can get the label for a specific review:\n",
        "train_labels[0]"
      ],
      "metadata": {
        "id": "_ayqqkRLskDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computer Vision"
      ],
      "metadata": {
        "id": "7jSwyrrrgRuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading libraries"
      ],
      "metadata": {
        "id": "l-wScOvOgT0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Lambda, Layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ],
      "metadata": {
        "id": "p0DEFpZ-KxJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the Data (CV1)"
      ],
      "metadata": {
        "id": "fMkYVRWT1YdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Class names in the CIFAR-10 dataset\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "Cq8p1PShsgrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the Data (CV2)"
      ],
      "metadata": {
        "id": "Tx2HDHDxfvxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "c7RJ6ObKfyI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the Data (CV3)"
      ],
      "metadata": {
        "id": "i7NajcJGf3CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "j6BpStcSgI-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot images**\n",
        "\n",
        "Plot some images from the dataset (CV1)"
      ],
      "metadata": {
        "id": "KJYmHEPpMP8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize a plot with 1 row and 10 columns\n",
        "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Plot one image from each class\n",
        "for i in range(10):\n",
        "    # Find the index of the first image of each class\n",
        "    index = np.where(train_labels.flatten() == i)[0][0]\n",
        "    img = train_images[index]\n",
        "\n",
        "    # Plot the image\n",
        "    axes[i].imshow(img, cmap=plt.cm.binary)\n",
        "    axes[i].set_title(class_names[i])\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1VbqZpqtMNVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "ApUSdXJLL_A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting images (CV1)"
      ],
      "metadata": {
        "id": "_RbR8Ov4fUOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize a plot with 1 row and 10 columns\n",
        "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Plot one image from each class\n",
        "for i in range(10):\n",
        "    # Find the index of the first image of each class\n",
        "    index = np.where(train_labels.flatten() == i)[0][0]\n",
        "    img = train_images[index]\n",
        "\n",
        "    # Plot the image\n",
        "    axes[i].imshow(img, cmap=plt.cm.binary)\n",
        "    axes[i].set_title(class_names[i])\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4330UZPDfWEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) Develop a model\n"
      ],
      "metadata": {
        "id": "x4z083ux9Ds1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##1) Prepare the data;\n",
        "- Vecorize inputs and targets\n",
        "- Turn data into tensors\n",
        "- Normalize values to have uniform ranges\n",
        "\n"
      ],
      "metadata": {
        "id": "gKj349OHtN-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Two roads we can take when preparing the data:\n",
        "\n",
        "1) Let lists be integer tensors and feed into an Embedding layer\n",
        "\n",
        "2) Multihot encode lists into vectors of 0s and 1s and feed into a Dense layer.\n"
      ],
      "metadata": {
        "id": "GbKMXJIHt5H_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a function that loops through the 10,000 dimensional vector, and inserts a 1 when there is a word."
      ],
      "metadata": {
        "id": "k-Uz5RAzuc7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Encoding the integer sequences via multi-hot encoding**\n",
        "\n",
        "I.e. Converting training and test data to a binary matrix"
      ],
      "metadata": {
        "id": "V7tI1vELu6K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "metadata": {
        "id": "8Mm05lBItUFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Defines a function to vectorize sequences with a default dimension size of 10,000.\n",
        "2.Creates a 2D NumPy array filled with zeros, with one row for each sequence and one column for each word in the specified dimension.\n",
        "3. Iterates over the sequences, with 'i' tracking the index of the current sequence.\n",
        "4. Iterates over each word index in the current sequence.\n",
        "5. Sets the value at position [i, j] in the results array to 1, indicating the presence of word 'j' in sequence 'i'.\n",
        "6. returns the results."
      ],
      "metadata": {
        "id": "a0DIcow-urtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*To see what the sample looks like now*"
      ],
      "metadata": {
        "id": "FxmnGlQavDXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]\n",
        "\n",
        "# or (from example 2) to look at the first 100 values\n",
        "x_train[10,1:100]"
      ],
      "metadata": {
        "id": "tvIkDWaPvFCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-hot dummy encoding"
      ],
      "metadata": {
        "id": "JtQlMce445Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results\n",
        "y_train = to_one_hot(train_labels)\n",
        "y_test = to_one_hot(test_labels)"
      ],
      "metadata": {
        "id": "80a5pYQl49cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Caution: By turning our lists into vectors of 0s and 1s this removes a lot of information, for instance in regards to positions of words.\n"
      ],
      "metadata": {
        "id": "8b3d4z6l5MJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizing the labels\n",
        "- i.e. converting the train and test labels into a NumPy array,\n",
        "- and changing the data_type to float32, i.e. containing sentiment labels (0 or 1) for the training dataset"
      ],
      "metadata": {
        "id": "WV5NJY7uvISn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "y_test = np.asarray(test_labels).astype(\"float32\")"
      ],
      "metadata": {
        "id": "g2op5ax6vTH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This conversion is typically done to ensure compatibility with TensorFlow/Keras, which prefers working with NumPy arrays of specific data types for inputs and labels. Using float32 helps reduce memory consumption and can improve computational efficiency on GPUs."
      ],
      "metadata": {
        "id": "9NqswCNBvTuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(train_labels)\n",
        "y_test = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "74jgs8T05f0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CV1 - One-hot encoding"
      ],
      "metadata": {
        "id": "yKaAM6ZChLVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "zSiPd52MhSlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2) Chose an evaluation protocol\n",
        "- Large input --> Hold-out,\n",
        "  - BUT: ordered data can misrepresent the sets.\n",
        "- Small input, or performance dependent on train-test split --> K-fold CV,\n",
        "  - BUT: more expensive, as it creates K models\n",
        "- Small input with higher need for precision --> Iterated K-fold CV with shuffling\n",
        "  - BUT: may be very expensive, as it creates P*K models\n",
        "\n"
      ],
      "metadata": {
        "id": "lLMCFghwtUzy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TMRlDdO0tbM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3) Beat a baseline\n",
        "- Filter out uninformative features\n",
        "- Select the correct architecture priors;\n",
        "    - Dense\n",
        "    - Images --> Convent\n",
        "    - Time-series --> Recurrent\n",
        "    - Text --> Transformer\n",
        "  - Select a good-enough training configuration\n",
        "    - Loss function\n",
        "    - Batch size\n",
        "    - Learning rate\n"
      ],
      "metadata": {
        "id": "umpf056Ztbxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: Input data is vectors and labels are scalars (1s and 0s)\n",
        "--> stack dense network.\n",
        "\n",
        "Model specifications\n",
        "\n",
        "- Loss function: binary_crossentropy\n",
        "- optimizer: msprop\n",
        "- epochs: 4\n",
        "- Batch size: 512\n",
        "- Validation: 1000\n",
        "\n"
      ],
      "metadata": {
        "id": "wRvguSdUwe_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two key architecture decisions:\n",
        "\n",
        "1) How many layers to use\n",
        "\n",
        "2) How many units to choose for each layer"
      ],
      "metadata": {
        "id": "33usd7dNw17h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture\n"
      ],
      "metadata": {
        "id": "oLw-iDqmx_9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# two representation layers, with one output layer\n",
        "# this is our architectre; where we put in our assumptions."
      ],
      "metadata": {
        "id": "VBZ-m2Yltf6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caution: Information bottlenecks can be created if the change in the number of neurons from one layer to the next is too extreme."
      ],
      "metadata": {
        "id": "z43mqz5J4kEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Relu: 0 if negative, else leave be\n",
        "- Softmax: Outputs a probability score for each target class\n",
        "- Sigmoid: Squish values into 0 or 1,\n",
        "  - I.e. a probability via losistic regression"
      ],
      "metadata": {
        "id": "5-N4Kl6R6GrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computer Vision"
      ],
      "metadata": {
        "id": "WODHi2Ziht8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV1 model building\n",
        "Building a convent without adding data augmentation"
      ],
      "metadata": {
        "id": "avbX6ENpNxD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(32, 32, 3))  # Input layer\n",
        "\n",
        "# Normalization layer\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "\n",
        "# First Convolutional Block\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Second Convolutional Block\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Third Convolutional Block\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Flatten and Dense Layers\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)  # 10 classes in CIFAR-10\n",
        "\n",
        "# Model creation\n",
        "model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "gNRAWfSvN3_E",
        "outputId": "6baf4bb0-4c26-422c-94ce-4bdf989f174e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ceac9dea9dcf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Normalization layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRescaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### CV1 model building with data augmentation"
      ],
      "metadata": {
        "id": "WAQDKyahs_Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "# Applying augmentation on the inputs\n",
        "x = data_augmentation(inputs)\n",
        "\n",
        "# Normalization layer\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "\n",
        "# Convolutional blocks and rest of the model\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Urr7qTQdtHFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Experiment with more data augmentation techniques"
      ],
      "metadata": {
        "id": "XVZ0G5EztQbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced data augmentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\", input_shape=(32, 32, 3)),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "        layers.RandomContrast(0.1),  # Adjusts the contrast\n",
        "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),  # Translates the image\n",
        "        # Potentially add more augmentation techniques here\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "# Applying enhanced augmentation on the inputs\n",
        "x = data_augmentation(inputs)\n",
        "\n",
        "# Continue with normalization and the rest of your model\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "69po_lgatO_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"more_aug_convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=100,\n",
        "                    validation_split=0.2, batch_size=256,\n",
        "                    callbacks = callbacks)"
      ],
      "metadata": {
        "id": "JOv8TjsOtYp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'history' is the return value from model.fit()\n",
        "history_dict = history.history\n",
        "\n",
        "# Extracting loss and accuracy history\n",
        "train_loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "train_accuracy = history_dict['accuracy']\n",
        "val_accuracy = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Training and validation loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Training and validation accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()  # Adjusts the plots to ensure they don't overlap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QNjKWiuAtcu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV2 Model building\n",
        "Building a convent without adding data augmentation\n"
      ],
      "metadata": {
        "id": "nsqIpKYLOybs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "ZBaisse-PDWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you define the 'base_model' after the augmentation and normalization\n",
        "# Ensure the 'input_tensor' argument in ResNet50 is replaced with 'input_shape'\n",
        "# if you are defining 'x' as the output of previous layers\n",
        "base_model = keras.applications.ResNet50(include_top=False,\n",
        "                                         weights='imagenet',\n",
        "                                         input_shape=(32, 32, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "# Define the input tensor for your model\n",
        "input_tensor = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Apply data augmentation to the inputs\n",
        "x = data_augmentation(input_tensor)\n",
        "\n",
        "# Apply the preprocess_input function\n",
        "x = Lambda(preprocess_input)(x)\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=input_tensor, outputs=predictions)"
      ],
      "metadata": {
        "id": "xvk-lbihOy8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV3 Model building (with data augmentation)\n",
        "Building a convent WITH data augmentation (CV3)\n",
        "\n",
        "#### Building a mini Xception model"
      ],
      "metadata": {
        "id": "P-1Hl-RciU1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "ItKiv84QjB7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = data_augmentation(inputs)\n",
        "\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
        "\n",
        "for size in [32, 64, 128, 256]:\n",
        "    residual = x\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "    residual = layers.Conv2D(\n",
        "        size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "tht_59LOjMaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Compilation and training"
      ],
      "metadata": {
        "id": "n8R4k2oNx846"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "wy-Csul1x8OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the optimizer rmsprop is always a decent default.\n",
        "\n",
        "Loss functions:\n",
        "\n",
        "Metrics:"
      ],
      "metadata": {
        "id": "b439OLYW6agB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Justification:\n",
        "\n",
        "- \"rmsprop\", because it's an excellent default.\n",
        "  - If we cannot get it to work with anything else, that an ADAm are the go-to's.\n",
        "\n",
        "- \"Binary_crossentropy\", because the outcome is binary\n",
        "\n",
        "- We monitor accuracy"
      ],
      "metadata": {
        "id": "HroGjZEeyE6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=50,\n",
        "                    validation_split=0.2, batch_size=256,\n",
        "                    callbacks = callbacks)"
      ],
      "metadata": {
        "id": "SFWhFNjEOPZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV1 Compiling and training\n"
      ],
      "metadata": {
        "id": "bXQIDff_OLHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=50,\n",
        "                    validation_split=0.2, batch_size=256,\n",
        "                    callbacks = callbacks)"
      ],
      "metadata": {
        "id": "Feom4Tigrdgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV2 Compiling and training"
      ],
      "metadata": {
        "id": "3Q4yRZaPOdZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile"
      ],
      "metadata": {
        "id": "nByTDxi5sXG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "loK2gWlVOc2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "PMEOHCxMsUVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"resnet50.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=256,\n",
        "                    validation_split=0.2,  # Use 20% of the data for validation\n",
        "                    callbacks=callbacks,  # Include the callbacks in training\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "_oK_PQqFsVQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV3 compile and train"
      ],
      "metadata": {
        "id": "7U9SokbHjX7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"mini_xception.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=100,\n",
        "                    validation_split=0.2, batch_size=256,\n",
        "                    callbacks = callbacks)"
      ],
      "metadata": {
        "id": "98siqN2gjb0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data,\n",
        "i.e. setting aside a validation set"
      ],
      "metadata": {
        "id": "8r6p7aMa03Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]\n",
        "\n",
        "# validation data is data that was not used for training."
      ],
      "metadata": {
        "id": "4IhecHV-yiiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caution: If the data is ordered, simply taking the first 10,000 is problematic\n",
        "- To know if ordered:\n",
        "    - Trial and error (try both), or\n",
        "    - Check distribution"
      ],
      "metadata": {
        "id": "cwsiI6hfyvDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=0) # Set verbose=0 to suppress the output\n",
        "\n",
        "# For each batch we run backpropagation, etc. and we do this for 20 rounds or \"epochs\".\n",
        "\n",
        "# Return validation accuracy for plotting outside the function\n",
        "return history.history['val_accuracy']\n"
      ],
      "metadata": {
        "id": "HeHWlgKa0sKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Validation"
      ],
      "metadata": {
        "id": "U1Y0LizFyjUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lQB8uG3Z0syN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the history for the validation loss\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Find the index of the minimum validation loss\n",
        "min_val_loss_epoch = val_loss.index(min(val_loss))\n",
        "\n",
        "print(f\"Epoch with minimum validation loss: {min_val_loss_epoch + 1}\")"
      ],
      "metadata": {
        "id": "xBCIYPFL00Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computer Vision"
      ],
      "metadata": {
        "id": "vhN8opYWkNng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV1 - Plot training and validation curves"
      ],
      "metadata": {
        "id": "WuUtV8ALpdso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Assuming 'history' is the return value from model.fit()\n",
        "history_dict = history.history\n",
        "\n",
        "# Extracting loss and accuracy history\n",
        "train_loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "train_accuracy = history_dict['accuracy']\n",
        "val_accuracy = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Training and validation loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Training and validation accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()  # Adjusts the plots to ensure they don't overlap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NDK9RHYVpixb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_best_val_loss_and_accuracy(history):\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Find the index of the best validation loss\n",
        "    best_val_loss_index = np.argmin(history_dict['val_loss'])\n",
        "\n",
        "    # Retrieve the best validation loss\n",
        "    best_val_loss = history_dict['val_loss'][best_val_loss_index]\n",
        "\n",
        "    # Retrieve the validation accuracy corresponding to the best validation loss\n",
        "    best_val_accuracy = history_dict['val_accuracy'][best_val_loss_index]\n",
        "\n",
        "    print(f\"Best Validation Loss: {best_val_loss}\")\n",
        "    print(f\"Validation Accuracy at Best Loss: {best_val_accuracy}\")"
      ],
      "metadata": {
        "id": "2G0L3vxlpoMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_best_val_loss_and_accuracy(history)"
      ],
      "metadata": {
        "id": "diR81U8ppqj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = keras.models.load_model(\"resnet50.keras\", safe_mode=False)\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "73Nww8CjptyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test data evaluation"
      ],
      "metadata": {
        "id": "Pd_6_nrpsxO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "sWQFjTc3sznR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV3 - Plot training and validation curves"
      ],
      "metadata": {
        "id": "4U0iei_pkP7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'history' is the return value from model.fit()\n",
        "history_dict = history.history\n",
        "\n",
        "# Extracting loss and accuracy history\n",
        "train_loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "train_accuracy = history_dict['accuracy']\n",
        "val_accuracy = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Training and validation loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Training and validation accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()  # Adjusts the plots to ensure they don't overlap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aiyIzL73kTnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def print_best_val_loss_and_accuracy(history):\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Find the index of the best validation loss\n",
        "    best_val_loss_index = np.argmin(history_dict['val_loss'])\n",
        "\n",
        "    # Retrieve the best validation loss\n",
        "    best_val_loss = history_dict['val_loss'][best_val_loss_index]\n",
        "\n",
        "    # Retrieve the validation accuracy corresponding to the best validation loss\n",
        "    best_val_accuracy = history_dict['val_accuracy'][best_val_loss_index]\n",
        "\n",
        "    print(f\"Best Validation Loss: {best_val_loss}\")\n",
        "    print(f\"Validation Accuracy at Best Loss: {best_val_accuracy}\")"
      ],
      "metadata": {
        "id": "3qyVKaF5kXio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_best_val_loss_and_accuracy(history)"
      ],
      "metadata": {
        "id": "xON37gItka1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV3 evaluation of best model on test set"
      ],
      "metadata": {
        "id": "VnDcXFJAkeql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = keras.models.load_model(\"mini_xception.keras\")"
      ],
      "metadata": {
        "id": "uO_2hExFkjcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "rS8XXQGoklXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gdhipFCJkouY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4) Develop an overfitting model\n",
        "- Add layers\n",
        "- Enlarge layers\n",
        "- Train on more epochs\n",
        "- Still not overfitting? Complicate it\n",
        "\n"
      ],
      "metadata": {
        "id": "YCFWbcqytgMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5) Regularize and tune;\n",
        "- Try different architectures (Add or remove layers)\n",
        "- Add dropout\n",
        "- (Regularization if small model, but rarely worth considering)\n",
        "- Tuning hyperparameters;\n",
        "  - Number of units per layer\n",
        "  - Optimizer learning rate\n",
        "- Iterate on data curation or feature engineering, by\n",
        "  - collecting and annotating more data,\n",
        "  - developing better features, or\n",
        "  - removing uninformative features\n",
        "\n",
        "Careful: Do not from the beginning create a grid search loop that goes through all these optionalities, as that woul create data leakage (besides it costing a house and a horse)"
      ],
      "metadata": {
        "id": "bIBHzAq3tlzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat the above batches with corresponing change, e.g. removed layer."
      ],
      "metadata": {
        "id": "Z4pl9Xq8tpRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurations of neurons to try\n",
        "neuron_configs = [(4, 4), (64, 4), (64, 64)]\n",
        "val_accuracies = []\n",
        "\n",
        "# Run training for each neuron configuration and collect validation accuracies\n",
        "for nl1, nl2 in neuron_configs:\n",
        "    val_acc = news_nn(nl1, nl2)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "# Plotting all the validation accuracies\n",
        "epochs = range(1, 21)\n",
        "for i, val_acc in enumerate(val_accuracies):\n",
        "    plt.plot(epochs, val_acc, label=f'Config {neuron_configs[i][0]}-{neuron_configs[i][1]} neurons')\n",
        "\n",
        "plt.title('Validation accuracy with varying neuron counts')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KNF1_9Ip68ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV2 - Fine-tuning a pre-trained ResNet50\n",
        "We we not able to beat a from-scratch approach using the frozen ResNet50. Let's unfreeze the last layer to see if it helps."
      ],
      "metadata": {
        "id": "SRtVKx5Up3kE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.ResNet50(include_top=False,\n",
        "                                         weights='imagenet',\n",
        "                                         input_shape=(32, 32, 3))\n",
        "base_model.trainable = False\n",
        "# To unfreeze the last layer, we set its 'trainable' attribute to True\n",
        "base_model.layers[-1].trainable = True\n",
        "\n",
        "# Define the input tensor for your model\n",
        "input_tensor = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Apply data augmentation to the inputs\n",
        "x = data_augmentation(input_tensor)\n",
        "\n",
        "# Apply the preprocess_input function\n",
        "x = Lambda(preprocess_input)(x)\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=input_tensor, outputs=predictions)"
      ],
      "metadata": {
        "id": "xVJ_iELpp-vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FPhk5-vzqDuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"resnet50_finetune.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]"
      ],
      "metadata": {
        "id": "wdfRN-jwqGZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=256,\n",
        "                    validation_split=0.2,  # Use 20% of the data for validation\n",
        "                    callbacks=callbacks,  # Include the callbacks in training\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "kFjTIm6MqGx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_best_val_loss_and_accuracy(history)"
      ],
      "metadata": {
        "id": "yc1ZdIElqJbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'history' is the return value from model.fit()\n",
        "history_dict = history.history\n",
        "\n",
        "# Extracting loss and accuracy history\n",
        "train_loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "train_accuracy = history_dict['accuracy']\n",
        "val_accuracy = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Training and validation loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Training and validation accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()  # Adjusts the plots to ensure they don't overlap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qo1W1bvqqL8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = keras.models.load_model(\"resnet50_finetune.keras\", safe_mode=False)\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "Z0tnwoQDqOh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy\n",
        "\n",
        "Stakeholder communication example: \"With these settings, the fraud detection model would have a 5% false negative rate and a 2.5% false positive rate. Every day, an average of 200 valid transactions would be flagged as fraudulent and sent for manual review, and an average of 14 fraudulent transactions would be missed. An average of 266 fraudulent transactions would be correctly caught.”\n",
        "\n",
        "Chose distribution; API, On-device etc., specify requirements and last but not least monitor and maintain."
      ],
      "metadata": {
        "id": "PBIx7hRCtpu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discussion"
      ],
      "metadata": {
        "id": "5-MhK3p1kxFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV1\n",
        "\n",
        "What's next? To further increase the performance of our model, we could make some tweaks here and there, like icreasing the number of filters in the convolutional layers can help the model learn more complex features. Similarly, adjusting the number of neurons in the dense layers might improve learning capacity.\n",
        "\n",
        "However, at this stage, gains from such changes are likely going to marginal.\n",
        "\n",
        "Instead, there are two things that would likely boost performance:\n",
        "\n",
        "1) More and better data! The data is greatly pixilated. Higher resolution data would allow us to build deeper models that generalize better.\n",
        "\n",
        "2) More and better tricks! Next in the course, we'll learn about advanced computer vision techniques that can push performance even further."
      ],
      "metadata": {
        "id": "0xDgXj0jticS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV2\n",
        "We were not able to beat the from-scratch approach despite having adjusted the weights in the last layer and running for twice the number of epochs. What are the ways forward? Here are a couple of suggestions:\n",
        "\n",
        "*   **Unfreeze more layers**. Fine-tuning more layers may allow the pretrained network to better adapt to the specifics of the dataset.\n",
        "\n",
        "*   **Advanced Data Augmentation**: Explore more sophisticated data augmentation techniques. Sometimes, introducing variations in the augmentation can help the model generalize better.\n",
        "\n",
        "*   **Try a different pre-trained model**. The problem might be ResNet50 itself. Keras includes many different pre-trained models. See here for a [list](https://keras.io/api/applications/).\n"
      ],
      "metadata": {
        "id": "9ZV1exwfqQGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CV3\n",
        "Test set accuracy of 78.1% with only 189,642 - our best model so far!\n",
        "\n",
        "How good is this compared the current state-of-the-art on CIFAR-10? On the benchmark overview, this would place us at position 218. This might not seem impressive, but if you look at the parameters counts of the models in the visinity, you'll notice the our mini xception model is much, much smaller.\n",
        "\n",
        "For instance, at position 206, we'll find a CCN Vision Transformer model with an accuracy of 83.36, but a parameter count of 906,075M! That's about 5 times more parameters than our 189,642 parameters.\n",
        "\n",
        "Further, we are beating other more complicated models like the Hybrid Vision Nystromformer at place 221 with an accuracy of 75.26 and 623,706 parameters. That's 3%-points lower accuracy with around 3 times more parameters. Not bad!\n",
        "\n",
        "Finally, we haven't even started tweaking our model yet. Based on the plots, we could lower the learning rate a bit a later epochs, to remove some noisy behavior. Adjusting dropout might also help a bit and the last dense layer. Of course, we could also build the model even deeper, but that would increase the parametrer count - hopefully while getting higher accuracy."
      ],
      "metadata": {
        "id": "UcAUbjI2kx8_"
      }
    }
  ]
}